# -*- coding: utf-8 -*-
"""
ä¸Šä¸‹æ–‡å·¥ç¨‹ - Context Engineering

æ¨¡ä»¿ Cursor çš„ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›ï¼š
1. ç»Ÿä¸€ä¸Šä¸‹æ–‡æ„å»ºï¼šå°†å¤šæºä¿¡æ¯æ•´åˆä¸ºç»“æ„åŒ–ä¸Šä¸‹æ–‡
2. ä¼˜å…ˆçº§æ’åºï¼šæ ¹æ®ç›¸å…³æ€§å¯¹ä¸Šä¸‹æ–‡æ’åº
3. Token é¢„ç®—ç®¡ç†ï¼šåœ¨é™åˆ¶å†…æœ€å¤§åŒ–ä¿¡æ¯é‡
4. åŠ¨æ€å‹ç¼©ï¼šæ™ºèƒ½å‹ç¼©è¿‡é•¿å†…å®¹
5. å¼•ç”¨è¿½è¸ªï¼šè®°å½•ä¿¡æ¯æ¥æºç”¨äºå¼•ç”¨

è¿™æ˜¯ Cursor èƒ½å¤Ÿç†è§£å¤æ‚é¡¹ç›®çš„å…³é”®èƒ½åŠ›ï¼
"""
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
from loguru import logger
import json
import tiktoken


class ContextSource(Enum):
    """ä¸Šä¸‹æ–‡æ¥æº"""
    USER_MESSAGE = "user_message"        # ç”¨æˆ·æ¶ˆæ¯
    CONVERSATION = "conversation"        # å¯¹è¯å†å²
    RAG = "rag"                          # çŸ¥è¯†åº“æ£€ç´¢
    FILE = "file"                        # æ–‡ä»¶å†…å®¹
    MEMORY = "memory"                    # é•¿æœŸè®°å¿†
    TOOL_RESULT = "tool_result"          # å·¥å…·æ‰§è¡Œç»“æœ
    SKILL = "skill"                      # æŠ€èƒ½æŒ‡ä»¤
    SYSTEM = "system"                    # ç³»ç»Ÿä¿¡æ¯


class ContextPriority(Enum):
    """ä¸Šä¸‹æ–‡ä¼˜å…ˆçº§"""
    CRITICAL = 1    # å¿…é¡»åŒ…å«
    HIGH = 2        # é«˜ä¼˜å…ˆçº§
    MEDIUM = 3      # ä¸­ä¼˜å…ˆçº§
    LOW = 4         # ä½ä¼˜å…ˆçº§


@dataclass
class ContextBlock:
    """
    ä¸Šä¸‹æ–‡å—
    
    è¡¨ç¤ºä¸€ä¸ªç‹¬ç«‹çš„ä¸Šä¸‹æ–‡å•å…ƒ
    """
    id: str
    source: ContextSource
    content: str
    priority: ContextPriority = ContextPriority.MEDIUM
    
    # å…ƒä¿¡æ¯
    title: str = ""
    citation: str = ""              # å¼•ç”¨æ ‡è¯†
    relevance_score: float = 0.0    # ç›¸å…³æ€§åˆ†æ•°
    
    # Token ä¿¡æ¯
    token_count: int = 0
    
    # æ—¶é—´æˆ³
    created_at: datetime = field(default_factory=datetime.now)
    
    # é¢å¤–æ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_formatted(self) -> str:
        """æ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬"""
        lines = []
        if self.title:
            lines.append(f"### {self.title}")
        if self.citation:
            lines.append(f"*æ¥æº: {self.citation}*")
        lines.append(self.content)
        return "\n".join(lines)


@dataclass 
class ContextWindow:
    """
    ä¸Šä¸‹æ–‡çª—å£
    
    ç®¡ç† Token é¢„ç®—å’Œå†…å®¹
    """
    max_tokens: int
    blocks: List[ContextBlock] = field(default_factory=list)
    
    @property
    def used_tokens(self) -> int:
        return sum(b.token_count for b in self.blocks)
    
    @property
    def remaining_tokens(self) -> int:
        return self.max_tokens - self.used_tokens
    
    @property
    def usage_percent(self) -> float:
        return (self.used_tokens / self.max_tokens) * 100 if self.max_tokens > 0 else 0


class ContextManager:
    """
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    æ ¸å¿ƒèƒ½åŠ›ï¼š
    1. æ”¶é›†å¤šæºä¸Šä¸‹æ–‡
    2. ä¼˜å…ˆçº§æ’åº
    3. Token é¢„ç®—ç®¡ç†
    4. æ™ºèƒ½å‹ç¼©
    5. ç»Ÿä¸€æ ¼å¼è¾“å‡º
    """
    
    # é»˜è®¤é…ç½®
    DEFAULT_MAX_TOKENS = 8000
    COMPRESSION_THRESHOLD = 0.9  # 90% æ—¶å¼€å§‹å‹ç¼©
    
    # å„æ¥æºçš„é»˜è®¤ä¼˜å…ˆçº§
    SOURCE_PRIORITIES = {
        ContextSource.USER_MESSAGE: ContextPriority.CRITICAL,
        ContextSource.SKILL: ContextPriority.HIGH,
        ContextSource.RAG: ContextPriority.HIGH,
        ContextSource.FILE: ContextPriority.HIGH,
        ContextSource.CONVERSATION: ContextPriority.MEDIUM,
        ContextSource.MEMORY: ContextPriority.MEDIUM,
        ContextSource.TOOL_RESULT: ContextPriority.MEDIUM,
        ContextSource.SYSTEM: ContextPriority.LOW,
    }
    
    def __init__(
        self,
        max_tokens: int = DEFAULT_MAX_TOKENS,
        model: str = "gpt-4",
    ):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            max_tokens: æœ€å¤§ Token æ•°
            model: ç”¨äº Token è®¡ç®—çš„æ¨¡å‹
        """
        self.max_tokens = max_tokens
        self.model = model
        
        # Token è®¡æ•°å™¨
        try:
            self.encoding = tiktoken.encoding_for_model(model)
        except Exception:
            self.encoding = tiktoken.get_encoding("cl100k_base")
        
        # ä¸Šä¸‹æ–‡æ”¶é›†å™¨
        self.blocks: List[ContextBlock] = []
        
        logger.info(f"ContextManager initialized with {max_tokens} tokens")
    
    def count_tokens(self, text: str) -> int:
        """è®¡ç®— Token æ•°"""
        try:
            return len(self.encoding.encode(text))
        except Exception:
            # é™çº§ï¼šä¼°ç®—
            return len(text) // 4
    
    def add(
        self,
        content: str,
        source: ContextSource,
        priority: Optional[ContextPriority] = None,
        title: str = "",
        citation: str = "",
        relevance_score: float = 0.0,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> ContextBlock:
        """
        æ·»åŠ ä¸Šä¸‹æ–‡å—
        
        Args:
            content: å†…å®¹
            source: æ¥æº
            priority: ä¼˜å…ˆçº§ï¼ˆNone åˆ™ä½¿ç”¨æ¥æºé»˜è®¤å€¼ï¼‰
            title: æ ‡é¢˜
            citation: å¼•ç”¨æ ‡è¯†
            relevance_score: ç›¸å…³æ€§åˆ†æ•°
            metadata: é¢å¤–å…ƒæ•°æ®
        
        Returns:
            åˆ›å»ºçš„ä¸Šä¸‹æ–‡å—
        """
        if priority is None:
            priority = self.SOURCE_PRIORITIES.get(source, ContextPriority.MEDIUM)
        
        block = ContextBlock(
            id=f"{source.value}_{len(self.blocks)}",
            source=source,
            content=content,
            priority=priority,
            title=title,
            citation=citation,
            relevance_score=relevance_score,
            token_count=self.count_tokens(content),
            metadata=metadata or {},
        )
        
        self.blocks.append(block)
        logger.debug(f"Added context block: {block.id} ({block.token_count} tokens)")
        
        return block
    
    def add_user_message(self, message: str) -> ContextBlock:
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        return self.add(
            content=message,
            source=ContextSource.USER_MESSAGE,
            title="ç”¨æˆ·æ¶ˆæ¯",
            priority=ContextPriority.CRITICAL,
        )
    
    def add_conversation_history(
        self,
        messages: List[Dict[str, str]],
        max_messages: int = 10,
    ) -> List[ContextBlock]:
        """æ·»åŠ å¯¹è¯å†å²"""
        blocks = []
        
        # å–æœ€è¿‘çš„æ¶ˆæ¯
        recent = messages[-max_messages:] if len(messages) > max_messages else messages
        
        for i, msg in enumerate(recent):
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            
            block = self.add(
                content=f"{role}: {content}",
                source=ContextSource.CONVERSATION,
                title=f"å¯¹è¯ #{len(messages) - len(recent) + i + 1}",
                priority=ContextPriority.MEDIUM,
                relevance_score=0.5 + (i * 0.05),  # è¶Šæ–°è¶Šç›¸å…³
            )
            blocks.append(block)
        
        return blocks
    
    def add_rag_results(
        self,
        results: List[Dict[str, Any]],
        max_results: int = 5,
    ) -> List[ContextBlock]:
        """æ·»åŠ  RAG æ£€ç´¢ç»“æœ"""
        blocks = []
        
        for i, result in enumerate(results[:max_results]):
            content = result.get("content", "")
            source = result.get("source", result.get("metadata", {}).get("source", "æœªçŸ¥æ¥æº"))
            score = result.get("score", 0.0)
            
            block = self.add(
                content=content,
                source=ContextSource.RAG,
                title=f"çŸ¥è¯†åº“ç»“æœ #{i+1}",
                citation=source,
                relevance_score=score,
                priority=ContextPriority.HIGH,
                metadata=result.get("metadata", {}),
            )
            blocks.append(block)
        
        return blocks
    
    def add_file_content(
        self,
        path: str,
        content: str,
        relevance_score: float = 0.8,
    ) -> ContextBlock:
        """æ·»åŠ æ–‡ä»¶å†…å®¹"""
        return self.add(
            content=content,
            source=ContextSource.FILE,
            title=f"æ–‡ä»¶: {path}",
            citation=path,
            relevance_score=relevance_score,
            priority=ContextPriority.HIGH,
        )
    
    def add_skill_instructions(
        self,
        skill_name: str,
        instructions: str,
        examples: Optional[List[str]] = None,
    ) -> ContextBlock:
        """æ·»åŠ æŠ€èƒ½æŒ‡ä»¤"""
        content_parts = [instructions]
        if examples:
            content_parts.append("\n**ç¤ºä¾‹:**")
            for ex in examples[:3]:
                content_parts.append(f"- {ex}")
        
        return self.add(
            content="\n".join(content_parts),
            source=ContextSource.SKILL,
            title=f"æŠ€èƒ½: {skill_name}",
            priority=ContextPriority.HIGH,
        )
    
    def add_memory(
        self,
        memories: List[Dict[str, Any]],
    ) -> List[ContextBlock]:
        """æ·»åŠ é•¿æœŸè®°å¿†"""
        blocks = []
        
        for mem in memories:
            content = mem.get("content", "")
            score = mem.get("score", 0.5)
            
            block = self.add(
                content=content,
                source=ContextSource.MEMORY,
                title="ç›¸å…³è®°å¿†",
                relevance_score=score,
                priority=ContextPriority.MEDIUM,
            )
            blocks.append(block)
        
        return blocks
    
    def add_tool_result(
        self,
        tool_name: str,
        result: str,
    ) -> ContextBlock:
        """æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœ"""
        return self.add(
            content=result,
            source=ContextSource.TOOL_RESULT,
            title=f"å·¥å…·ç»“æœ: {tool_name}",
            priority=ContextPriority.MEDIUM,
        )
    
    def build(
        self,
        compress_if_needed: bool = True,
    ) -> str:
        """
        æ„å»ºæœ€ç»ˆä¸Šä¸‹æ–‡
        
        Args:
            compress_if_needed: è¶…å‡ºé¢„ç®—æ—¶æ˜¯å¦å‹ç¼©
        
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        # 1. æŒ‰ä¼˜å…ˆçº§å’Œç›¸å…³æ€§æ’åº
        sorted_blocks = sorted(
            self.blocks,
            key=lambda b: (b.priority.value, -b.relevance_score),
        )
        
        # 2. é€‰æ‹©åœ¨é¢„ç®—å†…çš„å—
        selected = []
        used_tokens = 0
        
        for block in sorted_blocks:
            if used_tokens + block.token_count <= self.max_tokens:
                selected.append(block)
                used_tokens += block.token_count
            elif block.priority == ContextPriority.CRITICAL:
                # å¿…é¡»åŒ…å«çš„å†…å®¹ï¼Œå°è¯•å‹ç¼©
                if compress_if_needed:
                    compressed = self._compress_block(block, self.max_tokens - used_tokens)
                    if compressed:
                        selected.append(compressed)
                        used_tokens += compressed.token_count
        
        # 3. æŒ‰æ¥æºåˆ†ç»„
        grouped = self._group_by_source(selected)
        
        # 4. æ ¼å¼åŒ–è¾“å‡º
        output_parts = []
        
        for source, blocks in grouped.items():
            if not blocks:
                continue
            
            section_title = self._get_section_title(source)
            output_parts.append(f"## {section_title}\n")
            
            for block in blocks:
                output_parts.append(block.to_formatted())
                output_parts.append("")
        
        result = "\n".join(output_parts)
        
        logger.info(f"Built context: {used_tokens} tokens, {len(selected)} blocks")
        
        return result
    
    def _group_by_source(
        self,
        blocks: List[ContextBlock],
    ) -> Dict[ContextSource, List[ContextBlock]]:
        """æŒ‰æ¥æºåˆ†ç»„"""
        grouped = {}
        
        # å®šä¹‰æ¥æºé¡ºåº
        source_order = [
            ContextSource.SKILL,
            ContextSource.RAG,
            ContextSource.FILE,
            ContextSource.MEMORY,
            ContextSource.CONVERSATION,
            ContextSource.TOOL_RESULT,
            ContextSource.SYSTEM,
        ]
        
        for source in source_order:
            grouped[source] = [b for b in blocks if b.source == source]
        
        return grouped
    
    def _get_section_title(self, source: ContextSource) -> str:
        """è·å–æ¥æºçš„ç« èŠ‚æ ‡é¢˜"""
        titles = {
            ContextSource.SKILL: "ğŸ“‹ ä»»åŠ¡æŒ‡ä»¤",
            ContextSource.RAG: "ğŸ“š çŸ¥è¯†åº“å‚è€ƒ",
            ContextSource.FILE: "ğŸ“„ ç›¸å…³æ–‡ä»¶",
            ContextSource.MEMORY: "ğŸ’­ ç›¸å…³è®°å¿†",
            ContextSource.CONVERSATION: "ğŸ’¬ å¯¹è¯å†å²",
            ContextSource.TOOL_RESULT: "ğŸ”§ å·¥å…·ç»“æœ",
            ContextSource.SYSTEM: "â„¹ï¸ ç³»ç»Ÿä¿¡æ¯",
        }
        return titles.get(source, source.value)
    
    def _compress_block(
        self,
        block: ContextBlock,
        target_tokens: int,
    ) -> Optional[ContextBlock]:
        """å‹ç¼©ä¸Šä¸‹æ–‡å—"""
        if target_tokens <= 50:
            return None
        
        content = block.content
        current_tokens = block.token_count
        
        # ç®€å•æˆªæ–­
        if current_tokens > target_tokens:
            # ä¼°ç®—ä¿ç•™æ¯”ä¾‹
            ratio = target_tokens / current_tokens
            keep_chars = int(len(content) * ratio * 0.9)  # ç•™10%ä½™é‡
            
            compressed_content = content[:keep_chars] + "\n...(å†…å®¹å·²å‹ç¼©)"
            
            return ContextBlock(
                id=block.id + "_compressed",
                source=block.source,
                content=compressed_content,
                priority=block.priority,
                title=block.title,
                citation=block.citation,
                relevance_score=block.relevance_score,
                token_count=self.count_tokens(compressed_content),
                metadata=block.metadata,
            )
        
        return block
    
    def get_citations(self) -> List[Dict[str, str]]:
        """è·å–æ‰€æœ‰å¼•ç”¨"""
        citations = []
        
        for block in self.blocks:
            if block.citation:
                citations.append({
                    "id": block.id,
                    "source": block.source.value,
                    "citation": block.citation,
                })
        
        return citations
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        by_source = {}
        for block in self.blocks:
            source = block.source.value
            if source not in by_source:
                by_source[source] = {"count": 0, "tokens": 0}
            by_source[source]["count"] += 1
            by_source[source]["tokens"] += block.token_count
        
        return {
            "total_blocks": len(self.blocks),
            "total_tokens": sum(b.token_count for b in self.blocks),
            "max_tokens": self.max_tokens,
            "by_source": by_source,
        }
    
    def clear(self):
        """æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡"""
        self.blocks.clear()
        logger.debug("Context cleared")


# ä¾¿æ·å‡½æ•°ï¼šå¿«é€Ÿæ„å»ºä¸Šä¸‹æ–‡
def build_context(
    user_message: str,
    conversation: Optional[List[Dict[str, str]]] = None,
    rag_results: Optional[List[Dict[str, Any]]] = None,
    files: Optional[Dict[str, str]] = None,
    skill_instructions: Optional[str] = None,
    memories: Optional[List[Dict[str, Any]]] = None,
    max_tokens: int = 8000,
) -> str:
    """
    å¿«é€Ÿæ„å»ºä¸Šä¸‹æ–‡
    
    Args:
        user_message: ç”¨æˆ·æ¶ˆæ¯
        conversation: å¯¹è¯å†å²
        rag_results: RAG æ£€ç´¢ç»“æœ
        files: æ–‡ä»¶å†…å®¹ {path: content}
        skill_instructions: æŠ€èƒ½æŒ‡ä»¤
        memories: é•¿æœŸè®°å¿†
        max_tokens: æœ€å¤§ Token æ•°
    
    Returns:
        æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    """
    cm = ContextManager(max_tokens=max_tokens)
    
    # æ·»åŠ æŠ€èƒ½æŒ‡ä»¤
    if skill_instructions:
        cm.add_skill_instructions("å½“å‰ä»»åŠ¡", skill_instructions)
    
    # æ·»åŠ  RAG ç»“æœ
    if rag_results:
        cm.add_rag_results(rag_results)
    
    # æ·»åŠ æ–‡ä»¶å†…å®¹
    if files:
        for path, content in files.items():
            cm.add_file_content(path, content)
    
    # æ·»åŠ è®°å¿†
    if memories:
        cm.add_memory(memories)
    
    # æ·»åŠ å¯¹è¯å†å²
    if conversation:
        cm.add_conversation_history(conversation)
    
    return cm.build()
