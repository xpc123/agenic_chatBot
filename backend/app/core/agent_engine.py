# -*- coding: utf-8 -*-
"""
åŸºäº LangChain 1.0 çš„ Agent å®ç°
ä½¿ç”¨ create_agent + Middleware æ¨¡å¼

LangChain 1.0 æ ¸å¿ƒç‰¹æ€§:
- create_agent: æ ‡å‡† Agent åˆ›å»º API
- Middleware: å¯ç»„åˆçš„ä¸­é—´ä»¶æ¶æ„ï¼ˆbefore_model, after_model, wrap_tool_call ç­‰ï¼‰
- å†…ç½®ä¸­é—´ä»¶: SummarizationMiddleware, PIIMiddleware, HumanInTheLoopMiddleware ç­‰
- åŸºäº LangGraph: è‡ªåŠ¨æ”¯æŒæŒä¹…åŒ–ã€æµå¼è¾“å‡ºã€äººå·¥å®¡æ‰¹
"""
from typing import List, Dict, Any, Optional, AsyncGenerator, Callable
from dataclasses import dataclass
from loguru import logger

# LangChain 1.0 æ ¸å¿ƒå¯¼å…¥
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import (
    AgentMiddleware,
    SummarizationMiddleware,
    HumanInTheLoopMiddleware,
    ModelCallLimitMiddleware,
    ToolRetryMiddleware,
    ModelRetryMiddleware,
    PIIMiddleware,
    ModelFallbackMiddleware,
    ToolCallLimitMiddleware,
    TodoListMiddleware,
    before_model,
    after_model,
    wrap_tool_call,
    wrap_model_call,
    dynamic_prompt,
    ModelRequest,
    ModelResponse,
)
from langchain.tools import tool, ToolRuntime
from langchain.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain.chat_models import init_chat_model
from langgraph.checkpoint.memory import InMemorySaver

from ..models.chat import ChatMessage, MessageRole
from ..config import settings


# ==================== è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ç±»å‹ ====================

@dataclass
class AgentContext:
    """
    Agent è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
    
    ç”¨äºåœ¨ middleware å’Œ tools ä¹‹é—´ä¼ é€’è‡ªå®šä¹‰æ•°æ®
    """
    session_id: str = ""
    user_id: str = ""
    rag_enabled: bool = True
    extra_context: Optional[Dict[str, Any]] = None


# ==================== è‡ªå®šä¹‰ä¸­é—´ä»¶ ====================

class RAGContextMiddleware(AgentMiddleware):
    """
    ä¸Šä¸‹æ–‡æ³¨å…¥ä¸­é—´ä»¶
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. ç»Ÿä¸€ä¸Šä¸‹æ–‡æ¨¡å¼ï¼ˆæ¨èï¼‰ï¼šä½¿ç”¨ ContextManager é¢„æ„å»ºçš„ç»Ÿä¸€ä¸Šä¸‹æ–‡
    2. åˆ†æ•£ä¸Šä¸‹æ–‡æ¨¡å¼ï¼ˆå…¼å®¹ï¼‰ï¼šåˆ†åˆ«ä¼ å…¥ RAG ç»“æœå’Œ @è·¯å¾„å¼•ç”¨
    
    åœ¨è°ƒç”¨æ¨¡å‹å‰ï¼Œå°†ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°æç¤ºä¸­
    """
    
    def __init__(self):
        self.unified_context: Optional[str] = None  # ç»Ÿä¸€ä¸Šä¸‹æ–‡ï¼ˆæ¨èï¼‰
        self.rag_results: Optional[List[Dict[str, Any]]] = None
        self.path_context: Optional[Dict[str, Any]] = None
    
    def set_unified_context(self, unified_context: str):
        """
        è®¾ç½®ç»Ÿä¸€ä¸Šä¸‹æ–‡ï¼ˆæ¨èæ–¹å¼ï¼‰
        
        Args:
            unified_context: ç”± ContextManager.build() ç”Ÿæˆçš„ç»Ÿä¸€ä¸Šä¸‹æ–‡
        """
        self.unified_context = unified_context
        # æ¸…é™¤åˆ†æ•£ä¸Šä¸‹æ–‡
        self.rag_results = None
        self.path_context = None
    
    def set_context(
        self, 
        rag_results: Optional[List[Dict[str, Any]]] = None,
        path_context: Optional[Dict[str, Any]] = None
    ):
        """è®¾ç½®åˆ†æ•£ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        self.rag_results = rag_results
        self.path_context = path_context
        # æ¸…é™¤ç»Ÿä¸€ä¸Šä¸‹æ–‡
        self.unified_context = None
    
    def before_model(self, state: AgentState, runtime) -> Dict[str, Any] | None:
        """åœ¨è°ƒç”¨æ¨¡å‹å‰æ³¨å…¥ä¸Šä¸‹æ–‡"""
        context_content = None
        
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€ä¸Šä¸‹æ–‡
        if self.unified_context:
            context_content = self.unified_context
        else:
            # å…¼å®¹æ¨¡å¼ï¼šæ„å»ºåˆ†æ•£ä¸Šä¸‹æ–‡
            context_parts = []
            
            # æ³¨å…¥ RAG æ£€ç´¢ç»“æœ
            if self.rag_results:
                context_parts.append("## ğŸ“š çŸ¥è¯†åº“å‚è€ƒ")
                for i, doc in enumerate(self.rag_results[:5], 1):  # æœ€å¤š5æ¡
                    content = doc.get('content', '')[:500]
                    source = doc.get('source', 'unknown')
                    score = doc.get('score', 0)
                    context_parts.append(f"### å¼•ç”¨ {i} (ç›¸å…³åº¦: {score:.2f})")
                    context_parts.append(f"**æ¥æº**: {source}")
                    context_parts.append(f"**å†…å®¹**: {content}...")
                context_parts.append("")
            
            # æ³¨å…¥ @è·¯å¾„å¼•ç”¨å†…å®¹
            if self.path_context and self.path_context.get("formatted"):
                context_parts.append("## ğŸ“ å¼•ç”¨çš„æ–‡ä»¶å†…å®¹")
                context_parts.append(self.path_context["formatted"])
                context_parts.append("")
            
            if context_parts:
                context_content = "\n".join(context_parts)
        
        if context_content:
            # å°†ä¸Šä¸‹æ–‡ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ³¨å…¥åˆ°æ¶ˆæ¯åˆ—è¡¨å¼€å¤´
            context_message = SystemMessage(content=context_content)
            messages = list(state.get("messages", []))
            # åœ¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰æ’å…¥ä¸Šä¸‹æ–‡
            messages.insert(0, context_message)
            return {"messages": messages}
        
        return None
    
    def clear_context(self):
        """æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡"""
        self.unified_context = None
        self.rag_results = None
        self.path_context = None


@before_model
def log_model_request(request: ModelRequest) -> None:
    """è®°å½•æ¨¡å‹è°ƒç”¨æ—¥å¿—"""
    message_count = len(request.state.get("messages", []))
    logger.debug(f"Model request: {message_count} messages")


@after_model
def log_model_response(state: AgentState, response, runtime) -> None:
    """è®°å½•æ¨¡å‹å“åº”æ—¥å¿—"""
    if hasattr(response, 'content') and response.content:
        content_preview = response.content[:100] + "..." if len(response.content) > 100 else response.content
        logger.debug(f"Model response: {content_preview}")


@wrap_tool_call
async def enhanced_tool_error_handler(request, handler):
    """
    å¢å¼ºçš„å·¥å…·é”™è¯¯å¤„ç†ä¸­é—´ä»¶ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
    
    æä¾›æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯å’Œè‡ªåŠ¨é‡è¯•å»ºè®®
    """
    try:
        return await handler(request)
    except Exception as e:
        tool_name = request.tool_call.get("name", "unknown")
        error_msg = str(e)
        
        logger.error(f"Tool '{tool_name}' failed: {error_msg}")
        
        # è¿”å›å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        return ToolMessage(
            content=(
                f"âš ï¸ å·¥å…· '{tool_name}' æ‰§è¡Œå¤±è´¥\n"
                f"é”™è¯¯: {error_msg}\n"
                f"å»ºè®®: è¯·æ£€æŸ¥è¾“å…¥å‚æ•°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¨åé‡è¯•ã€‚"
            ),
            tool_call_id=request.tool_call["id"]
        )


# ==================== ä¸» Agent ç±» ====================

class ExecutorAgent:
    """
    æ‰§è¡Œ Agent - åº•å±‚æ‰§è¡Œå¼•æ“
    
    è¿™æ˜¯çœŸæ­£çš„ Agentï¼ŒåŸºäº LangChain 1.0 create_agent å®ç°ï¼Œè´Ÿè´£:
    - æ‰§è¡Œ ReAct å¾ªç¯ï¼ˆReason â†’ Act â†’ Observeï¼‰
    - ç®¡ç† Middlewareï¼ˆå‹ç¼©ã€PIIã€äººå·¥å®¡æ‰¹ç­‰ï¼‰
    - å¤„ç†å·¥å…·è°ƒç”¨
    - æ³¨å…¥ä¸Šä¸‹æ–‡åˆ° LLM
    - æµå¼è¾“å‡ºç»“æœ
    
    æ ¸å¿ƒç‰¹æ€§:
    - ä½¿ç”¨ create_agent æ„å»ºæ ‡å‡† ReAct å¾ªç¯
    - æ”¯æŒä¸°å¯Œçš„å†…ç½® Middleware
    - è‡ªåŠ¨æŒä¹…åŒ–å’Œæµå¼è¾“å‡º
    - åŠ¨æ€å·¥å…·å’Œæ¨¡å‹é€‰æ‹©
    - è‡ªå®šä¹‰ä¸Šä¸‹æ–‡æ³¨å…¥
    
    ä½¿ç”¨ç¤ºä¾‹:
    ```python
    agent = ExecutorAgent(
        tools=[my_tool],
        model="gpt-4o",
        enable_summarization=True,
    )
    
    async for chunk in agent.chat(message, session_id):
        print(chunk)
    ```
    """
    
    def __init__(
        self,
        tools: Optional[List[Callable]] = None,
        model: Optional[str] = None,
        provider: str = "openai", # æ–°å¢ provider å‚æ•°
        use_tool_registry: bool = True,  # æ–°å¢ï¼šä½¿ç”¨å·¥å…·æ³¨å†Œè¡¨
        tool_categories: Optional[List[str]] = None,  # æ–°å¢ï¼šå·¥å…·åˆ†ç±»è¿‡æ»¤
        enable_summarization: bool = False,  # é»˜è®¤ç¦ç”¨ï¼Œéœ€è¦ OpenAI key
        enable_pii_filter: bool = False,
        enable_human_in_loop: bool = False,
        human_approval_tools: Optional[List[str]] = None,
        enable_todo_list: bool = False,
        enable_model_fallback: bool = False,  # é»˜è®¤ç¦ç”¨ï¼Œéœ€è¦ OpenAI/Anthropic key
        fallback_models: Optional[List[str]] = None,
        max_iterations: Optional[int] = None,
    ):
        """
        åˆå§‹åŒ– LangChain Agent
        
        Args:
            tools: å·¥å…·åˆ—è¡¨ï¼ˆä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰ï¼‰ï¼Œå¦‚æœä¸º None ä¸” use_tool_registry=Trueï¼Œåˆ™ä»æ³¨å†Œè¡¨è·å–
            model: æ¨¡å‹æ ‡è¯†ç¬¦ (å¦‚ "gpt-4o", "claude-sonnet-4-5-20250929")
            provider: æ¨¡å‹æä¾›å•† ("openai", "anthropic", "jedai", etc.)
            use_tool_registry: æ˜¯å¦ä½¿ç”¨å·¥å…·æ³¨å†Œè¡¨ï¼ˆé»˜è®¤ Trueï¼‰
            tool_categories: ä»æ³¨å†Œè¡¨è·å–å·¥å…·æ—¶çš„åˆ†ç±»è¿‡æ»¤ï¼ˆå¦‚ ["builtin", "extended"]ï¼‰
            enable_summarization: æ˜¯å¦å¯ç”¨å¯¹è¯å†å²è‡ªåŠ¨å‹ç¼©
            enable_pii_filter: æ˜¯å¦å¯ç”¨ PII è¿‡æ»¤
            enable_human_in_loop: æ˜¯å¦å¯ç”¨äººå·¥å®¡æ‰¹
            human_approval_tools: éœ€è¦äººå·¥å®¡æ‰¹çš„å·¥å…·åç§°åˆ—è¡¨
            enable_todo_list: æ˜¯å¦å¯ç”¨ä»»åŠ¡åˆ—è¡¨åŠŸèƒ½
            enable_model_fallback: æ˜¯å¦å¯ç”¨æ¨¡å‹æ•…éšœåˆ‡æ¢
            fallback_models: å¤‡ç”¨æ¨¡å‹åˆ—è¡¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        # å¤„ç†å·¥å…·åˆ—è¡¨
        if tools is not None:
            # å¦‚æœæ˜¾å¼ä¼ å…¥å·¥å…·ï¼Œä½¿ç”¨ä¼ å…¥çš„
            self.tools = tools
        elif use_tool_registry:
            # ä»å·¥å…·æ³¨å†Œè¡¨è·å–
            registry = get_tool_registry()
            if registry.get_tool_names():
                # æ³¨å†Œè¡¨å·²åˆå§‹åŒ–
                if tool_categories:
                    self.tools = registry.get_tools(categories=set(tool_categories))
                else:
                    self.tools = registry.get_all_tools()
                logger.info(f"ğŸ“¦ ä»æ³¨å†Œè¡¨åŠ è½½äº† {len(self.tools)} ä¸ªå·¥å…·")
            else:
                # æ³¨å†Œè¡¨ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å·¥å…·
                self.tools = get_basic_tools()
                logger.info(f"ğŸ“¦ ä½¿ç”¨é»˜è®¤å·¥å…·: {len(self.tools)} ä¸ª")
        else:
            # ä¸ä½¿ç”¨æ³¨å†Œè¡¨ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·
            self.tools = get_basic_tools()
        
        self.model_name = model or settings.OPENAI_MODEL
        self.provider = provider # ä¿å­˜ provider
        self.max_iterations = max_iterations or settings.MAX_ITERATIONS
        
        # æŒä¹…åŒ– checkpointer
        self.checkpointer = InMemorySaver()
        
        # åˆå§‹åŒ– RAG ä¸Šä¸‹æ–‡ä¸­é—´ä»¶
        self.rag_context_middleware = RAGContextMiddleware()
        
        # æ„å»ºä¸­é—´ä»¶åˆ—è¡¨
        self.middleware = self._build_middleware(
            enable_summarization=enable_summarization,
            enable_pii_filter=enable_pii_filter,
            enable_human_in_loop=enable_human_in_loop,
            human_approval_tools=human_approval_tools,
            enable_todo_list=enable_todo_list,
            enable_model_fallback=enable_model_fallback,
            fallback_models=fallback_models,
        )
        
        # æ„å»º Agent
        self.agent = self._build_agent()
        
        logger.info(
            f"ExecutorAgent initialized: model={self.model_name}, "
            f"tools={len(self.tools)}, middleware={len(self.middleware)}"
        )
    
    def _build_middleware(
        self,
        enable_summarization: bool,
        enable_pii_filter: bool,
        enable_human_in_loop: bool,
        human_approval_tools: Optional[List[str]],
        enable_todo_list: bool,
        enable_model_fallback: bool,
        fallback_models: Optional[List[str]],
    ) -> List:
        """æ„å»ºä¸­é—´ä»¶åˆ—è¡¨"""
        middleware = []
        
        # 1. RAG ä¸Šä¸‹æ–‡æ³¨å…¥ï¼ˆè‡ªå®šä¹‰ï¼‰
        middleware.append(self.rag_context_middleware)
        
        # 2. æ—¥å¿—ä¸­é—´ä»¶ (æš‚æ—¶ç¦ç”¨ï¼Œå¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜)
        # middleware.extend([log_model_request, log_model_response])
        
        # 3. æ¨¡å‹è°ƒç”¨é™åˆ¶ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        middleware.append(
            ModelCallLimitMiddleware(
                thread_limit=self.max_iterations * 2,
                run_limit=self.max_iterations,
                exit_behavior="end",
            )
        )
        
        # 4. å·¥å…·è°ƒç”¨é™åˆ¶
        middleware.append(
            ToolCallLimitMiddleware(
                thread_limit=50,
                run_limit=20,
            )
        )
        
        # 5. å·¥å…·é‡è¯•ï¼ˆå¤„ç†ä¸´æ—¶å¤±è´¥ï¼‰
        middleware.append(
            ToolRetryMiddleware(
                max_retries=3,
                backoff_factor=2.0,
                initial_delay=1.0,
            )
        )
        
        # 6. æ¨¡å‹é‡è¯•ï¼ˆå¤„ç† API ä¸´æ—¶å¤±è´¥ï¼‰
        middleware.append(
            ModelRetryMiddleware(
                max_retries=3,
                backoff_factor=2.0,
                initial_delay=1.0,
            )
        )
        
        # 7. å¢å¼ºçš„å·¥å…·é”™è¯¯å¤„ç†ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
        middleware.append(enhanced_tool_error_handler)
        
        # 8. æ¨¡å‹æ•…éšœåˆ‡æ¢ï¼ˆå¯é€‰ï¼‰
        if enable_model_fallback:
            fallbacks = fallback_models or ["gpt-4o-mini", "claude-3-5-sonnet-20241022"]
            middleware.append(ModelFallbackMiddleware(*fallbacks))
        
        # 9. å†å²å‹ç¼©ï¼ˆå¯é€‰ï¼‰
        if enable_summarization:
            middleware.append(
                SummarizationMiddleware(
                    model="gpt-4o-mini",  # ä½¿ç”¨è¾ƒå°æ¨¡å‹è¿›è¡Œæ‘˜è¦
                    trigger=("tokens", 4000),
                    keep=("messages", 20),
                )
            )
        
        # 10. PII è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
        if enable_pii_filter:
            middleware.extend([
                PIIMiddleware("email", strategy="redact", apply_to_input=True),
                PIIMiddleware("phone_number", strategy="mask", apply_to_input=True),
                PIIMiddleware("credit_card", strategy="block", apply_to_input=True),
            ])
        
        # 11. ä»»åŠ¡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        if enable_todo_list:
            middleware.append(TodoListMiddleware())
        
        # 12. äººå·¥å®¡æ‰¹ï¼ˆå¯é€‰ï¼‰
        if enable_human_in_loop and human_approval_tools:
            interrupt_config = {
                tool_name: {"allowed_decisions": ["approve", "edit", "reject"]}
                for tool_name in human_approval_tools
            }
            middleware.append(
                HumanInTheLoopMiddleware(interrupt_on=interrupt_config)
            )
        
        return middleware
    
    def _build_agent(self):
        """æ„å»º LangChain 1.0 Agent"""
        system_prompt = self._get_system_prompt()
        
        # è·å– LLM å®¢æˆ·ç«¯å®ä¾‹
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ get_llm_client æ¥è·å–ç»Ÿä¸€ç®¡ç†çš„ LLM å®ä¾‹
        # è¿™æ ·å¯ä»¥å¤ç”¨ client.py ä¸­çš„åˆå§‹åŒ–é€»è¾‘ï¼ˆåŒ…æ‹¬ JedAI çš„ç‰¹æ®Šå¤„ç†ï¼‰
        from ..llm import get_llm_client
        llm_client = get_llm_client(provider=self.provider, model=self.model_name)
        
        # ä½¿ç”¨ llm_client.llm ä½œä¸ºæ¨¡å‹å®ä¾‹
        # create_agent æ”¯æŒä¼ å…¥å·²åˆå§‹åŒ–çš„ BaseChatModel
        agent = create_agent(
            model=llm_client.llm, 
            tools=self.tools,
            system_prompt=system_prompt,
            middleware=self.middleware,
            checkpointer=self.checkpointer,
            context_schema=AgentContext,
        )
        
        return agent
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤º"""
        return """ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ AI åŠ©æ‰‹ï¼Œå…·æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š

## æ ¸å¿ƒèƒ½åŠ›

1. **å·¥å…·è°ƒç”¨**: ä½ å¯ä»¥ä½¿ç”¨æä¾›çš„å·¥å…·æ¥è·å–ä¿¡æ¯ã€æ‰§è¡Œæ“ä½œ
2. **ä¸Šä¸‹æ–‡ç†è§£**: ä½ ä¼šæ”¶åˆ°æ¥è‡ªçŸ¥è¯†åº“å’Œæ–‡ä»¶å¼•ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
3. **å¤šæ­¥æ¨ç†**: å¯¹äºå¤æ‚é—®é¢˜ï¼Œä½ ä¼šåˆ†æ­¥éª¤æ€è€ƒå’Œæ‰§è¡Œ
4. **ä»»åŠ¡è§„åˆ’**: å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œå…ˆåˆ¶å®šè®¡åˆ’å†é€æ­¥æ‰§è¡Œ

## å·¥ä½œåŸåˆ™

- ä»”ç»†é˜…è¯»ç”¨æˆ·é—®é¢˜ï¼Œç†è§£çœŸæ­£çš„æ„å›¾
- å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå…ˆæ€è€ƒéœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼Œå†è°ƒç”¨ç›¸åº”å·¥å…·
- ä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆçŸ¥è¯†åº“ã€æ–‡ä»¶å†…å®¹ï¼‰æ¥å¢å¼ºå›ç­”
- å›ç­”è¦å‡†ç¡®ã€æœ‰å¸®åŠ©ã€æ ¼å¼æ¸…æ™°
- å¦‚æœä¸ç¡®å®šï¼Œå¦è¯šè¯´æ˜å¹¶æä¾›å¯èƒ½çš„æ–¹å‘
- ä¼˜å…ˆä½¿ç”¨ä¸­æ–‡å›å¤

## å¼•ç”¨è§„èŒƒ

å½“ä½¿ç”¨çŸ¥è¯†åº“æˆ–æ–‡ä»¶å†…å®¹æ—¶ï¼Œè¯·åœ¨å›ç­”ä¸­æ ‡æ³¨æ¥æºã€‚
æ ¼å¼: [æ¥æº: æ–‡ä»¶åæˆ–é“¾æ¥]

## å·¥å…·ä½¿ç”¨å»ºè®®

- æ•°å­¦è®¡ç®—: ä½¿ç”¨ calculator å·¥å…·
- è·å–å½“å‰æ—¶é—´: ä½¿ç”¨ get_current_time å·¥å…·
- å…¶ä»–å·¥å…·: æ ¹æ®å·¥å…·æè¿°é€‰æ‹©åˆé€‚çš„å·¥å…·"""
    
    def add_tool(self, tool_func: Callable):
        """
        åŠ¨æ€æ·»åŠ å·¥å…·
        
        Args:
            tool_func: ä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰çš„å‡½æ•°
        """
        self.tools.append(tool_func)
        # é‡æ–°æ„å»º Agent
        self.agent = self._build_agent()
        logger.info(f"Tool added: {tool_func.__name__}")
    
    def set_context(
        self,
        unified_context: Optional[str] = None,
        rag_results: Optional[List[Dict[str, Any]]] = None,
        path_context: Optional[Dict[str, Any]] = None,
    ):
        """
        è®¾ç½®å¯¹è¯ä¸Šä¸‹æ–‡
        
        Args:
            unified_context: ç»Ÿä¸€æ„å»ºçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆæ¨èä½¿ç”¨ ContextManagerï¼‰
            rag_results: RAG æ£€ç´¢ç»“æœï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
            path_context: @è·¯å¾„å¼•ç”¨ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        """
        if unified_context:
            # ä½¿ç”¨ç»Ÿä¸€ä¸Šä¸‹æ–‡ï¼ˆContext Engineeringï¼‰
            self.rag_context_middleware.set_unified_context(unified_context)
        else:
            # å…¼å®¹æ—§æ¥å£
            self.rag_context_middleware.set_context(rag_results, path_context)
    
    async def chat(
        self,
        message: str,
        session_id: str,
        unified_context: Optional[str] = None,
        rag_results: Optional[List[Dict[str, Any]]] = None,
        path_context: Optional[Dict[str, Any]] = None,
        context: Optional[AgentContext] = None,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¯¹è¯æ¥å£
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ IDï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰
            unified_context: ç»Ÿä¸€æ„å»ºçš„ä¸Šä¸‹æ–‡ï¼ˆæ¨èï¼Œç”± ContextManager ç”Ÿæˆï¼‰
            rag_results: RAG æ£€ç´¢ç»“æœï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
            path_context: @è·¯å¾„å¼•ç”¨ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
            context: è‡ªå®šä¹‰è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
        
        Yields:
            äº‹ä»¶å­—å…¸ {"type": "text|tool_call|tool_result|thinking|error", "content": ...}
        """
        # è®¾ç½®ä¸Šä¸‹æ–‡ï¼ˆä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€ä¸Šä¸‹æ–‡ï¼‰
        self.set_context(unified_context, rag_results, path_context)
        
        # å‡†å¤‡è¾“å…¥
        input_data = {
            "messages": [{"role": "user", "content": message}]
        }
        
        # é…ç½®ï¼ˆä½¿ç”¨ session_id å®ç°ä¼šè¯æŒä¹…åŒ–ï¼‰
        config = {"configurable": {"thread_id": session_id}}
        
        # è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
        runtime_context = context or AgentContext(session_id=session_id)
        
        # è·Ÿè¸ªå·²å¤„ç†çš„å·¥å…·è°ƒç”¨å’Œç»“æœï¼Œé¿å…é‡å¤
        seen_tool_calls = set()
        seen_tool_results = set()
        last_text_content = None
        
        try:
            # æµå¼æ‰§è¡Œ
            async for chunk in self.agent.astream(
                input_data, 
                config, 
                stream_mode="values",
                context=runtime_context,
            ):
                # è§£ææœ€æ–°æ¶ˆæ¯
                messages = chunk.get("messages", [])
                if not messages:
                    continue
                
                last_message = messages[-1]
                
                # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå»é‡ï¼‰
                if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                    for tool_call in last_message.tool_calls:
                        tool_call_id = tool_call.get("id", "")
                        if tool_call_id and tool_call_id in seen_tool_calls:
                            continue  # è·³è¿‡å·²å¤„ç†çš„å·¥å…·è°ƒç”¨
                        seen_tool_calls.add(tool_call_id)
                        
                        yield {
                            "type": "tool_call",
                            "content": f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}",
                            "metadata": {
                                "tool": tool_call["name"],
                                "args": tool_call.get("args", {}),
                                "tool_call_id": tool_call_id
                            }
                        }
                
                # å¤„ç†å·¥å…·ç»“æœï¼ˆå»é‡ï¼‰
                elif isinstance(last_message, ToolMessage):
                    tool_call_id = last_message.tool_call_id
                    if tool_call_id in seen_tool_results:
                        continue  # è·³è¿‡å·²å¤„ç†çš„å·¥å…·ç»“æœ
                    seen_tool_results.add(tool_call_id)
                    
                    yield {
                        "type": "tool_result",
                        "content": f"âœ… å·¥å…·ç»“æœ",
                        "metadata": {
                            "tool_call_id": tool_call_id,
                            "result": last_message.content[:500]
                        }
                    }
                
                # å¤„ç† AI æœ€ç»ˆå›å¤ï¼ˆå»é‡ï¼‰
                elif hasattr(last_message, "content") and last_message.content:
                    # åªæœ‰å½“æ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶æ‰æ˜¯æœ€ç»ˆå›å¤
                    if not hasattr(last_message, "tool_calls") or not last_message.tool_calls:
                        # é¿å…é‡å¤å‘é€ç›¸åŒå†…å®¹
                        if last_message.content != last_text_content:
                            last_text_content = last_message.content
                            yield {
                                "type": "text",
                                "content": last_message.content
                            }
        
        except Exception as e:
            logger.error(f"Agent execution error: {e}")
            yield {
                "type": "error",
                "content": f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}"
            }
        
        finally:
            # æ¸…ç†ä¸Šä¸‹æ–‡
            self.rag_context_middleware.clear_context()
    
    def invoke(
        self,
        message: str,
        session_id: str,
        rag_results: Optional[List[Dict[str, Any]]] = None,
        path_context: Optional[Dict[str, Any]] = None,
        context: Optional[AgentContext] = None,
    ) -> str:
        """
        åŒæ­¥è°ƒç”¨æ¥å£ï¼ˆéæµå¼ï¼‰
        
        Returns:
            æœ€ç»ˆå›å¤æ–‡æœ¬
        """
        self.set_context(rag_results, path_context)
        
        input_data = {
            "messages": [{"role": "user", "content": message}]
        }
        config = {"configurable": {"thread_id": session_id}}
        runtime_context = context or AgentContext(session_id=session_id)
        
        try:
            result = self.agent.invoke(input_data, config, context=runtime_context)
            
            # æå–æœ€ç»ˆå›å¤
            messages = result.get("messages", [])
            for msg in reversed(messages):
                if hasattr(msg, "content") and msg.content:
                    if not hasattr(msg, "tool_calls") or not msg.tool_calls:
                        return msg.content
            
            return ""
        
        finally:
            self.rag_context_middleware.clear_context()


# ==================== å†…ç½®å·¥å…·å¯¼å…¥ ====================

from .tools import (
    calculator,
    get_current_time,
    get_current_date,
    search_web,
    get_builtin_tools,
    get_basic_tools,
    get_extended_tools,
)

from .tool_registry import (
    ToolRegistry,
    ToolPermission,
    get_tool_registry,
)


# ==================== å…¨å±€å·¥å…·æ³¨å†Œè¡¨ ====================

def init_tool_registry(
    load_builtin: bool = True,
    load_extended: bool = True,
    api_config_path: Optional[str] = None,
) -> ToolRegistry:
    """
    åˆå§‹åŒ–å…¨å±€å·¥å…·æ³¨å†Œè¡¨
    
    Args:
        load_builtin: æ˜¯å¦åŠ è½½å†…ç½®å·¥å…·
        load_extended: æ˜¯å¦åŠ è½½æ‰©å±•å·¥å…·ï¼ˆHTTPã€ç³»ç»Ÿä¿¡æ¯ç­‰ï¼‰
        api_config_path: API å·¥å…·é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        åˆå§‹åŒ–åçš„å·¥å…·æ³¨å†Œè¡¨
    """
    registry = get_tool_registry()
    
    # åŠ è½½å†…ç½®å·¥å…·
    if load_builtin:
        builtin_tools = get_builtin_tools()
        count = registry.register_many(
            builtin_tools, 
            permission=ToolPermission.PUBLIC, 
            category="builtin"
        )
        logger.info(f"ğŸ“¦ åŠ è½½äº† {count} ä¸ªå†…ç½®å·¥å…·")
    
    # åŠ è½½æ‰©å±•å·¥å…·
    if load_extended:
        extended_tools = get_extended_tools()
        count = registry.register_many(
            extended_tools,
            permission=ToolPermission.PUBLIC,
            category="extended"
        )
        logger.info(f"ğŸ”§ åŠ è½½äº† {count} ä¸ªæ‰©å±•å·¥å…·")
    
    # åŠ è½½ API å·¥å…·é…ç½®
    if api_config_path:
        import os
        if os.path.exists(api_config_path):
            count = registry.load_from_config(api_config_path)
            logger.info(f"ğŸŒ ä»é…ç½®åŠ è½½äº† {count} ä¸ª API å·¥å…·")
        else:
            logger.warning(f"API é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {api_config_path}")
    
    return registry


def get_tools_from_registry(
    categories: Optional[List[str]] = None,
    exclude_tools: Optional[List[str]] = None,
) -> List:
    """
    ä»æ³¨å†Œè¡¨è·å–å·¥å…·åˆ—è¡¨
    
    Args:
        categories: è¦åŒ…å«çš„åˆ†ç±»åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºå…¨éƒ¨ï¼‰
        exclude_tools: è¦æ’é™¤çš„å·¥å…·åç§°åˆ—è¡¨
    
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    registry = get_tool_registry()
    
    # è·å–æ‰€æœ‰å¯ç”¨çš„å·¥å…·
    if categories:
        tools = registry.get_tools(categories=set(categories))
    else:
        tools = registry.get_all_tools()
    
    # æ’é™¤æŒ‡å®šå·¥å…·
    if exclude_tools:
        tools = [t for t in tools if t.name not in exclude_tools]
    
    return tools


# å‘åå…¼å®¹åˆ«å
AgentExecutor = ExecutorAgent
